{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#GENRATING DRAGONS\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "#print(randint(0, 9)) results in a number from [0,9]\n",
    "\n",
    "#DRAGON SECTS\n",
    "#https://pathfinderwiki.com/wiki/Dragon#Draconic_septs\n",
    "#metalic dragons=Good brass, copper, bronze, silver, and gold\n",
    "#chromatic dragons=Evil \"white\", \"black\", \"green\", \"blue\", \"red\" \n",
    "#Primal dragons=Chaotic brine, cloud, crystal, magma, and umbral\n",
    "#Outer dragons=Lawful lunar, solar, time, void, vortex\n",
    "\n",
    "#good\n",
    "metallic_dragons=[\"brass\", \"copper\", \"bronze\", \"silver\", \"gold\"]\n",
    "\n",
    "#evil\n",
    "chromatic_dragons=[\"white\", \"black\", \"green\", \"blue\", \"red\"]\n",
    "\n",
    "#chaotic\n",
    "primal_dragons=[\"brine\", \"cloud\", \"crystal\", \"magma\", \"umbral\"]\n",
    "\n",
    "#lawful\n",
    "outer_dragons=[\"lunar\", \"solar\", \"time\", \"void\", \"vortex\"]\n",
    "\n",
    "\n",
    "#dragons_sects[type][subtype]\n",
    "dragon_sects =[metallic_dragons,chromatic_dragons,primal_dragons,outer_dragons]\n",
    "\n",
    "#ALIGNMENTS\n",
    "law_chaos=[\"lawful\",\"lawful\",\"neutral\",\"chaotic\",\"chaotic\"]\n",
    "good_evil=[\"good\",\"good\",\"neutral\",\"evil\",\"evil\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#return dragon as a string    \n",
    "def generateDragon():    \n",
    "\n",
    "    sect_nr=randint(0,len(dragon_sects)-1)\n",
    "    \n",
    "    subsect_nr=randint(0,len(dragon_sects[sect_nr])-1)\n",
    "    \n",
    "    lawfulness_nr=randint(0,len(law_chaos)-1)   \n",
    "    \n",
    "    morality_nr=randint(0,len(good_evil)-1)\n",
    "    \n",
    "    return law_chaos[lawfulness_nr]+\" \"+good_evil[morality_nr]+\" \"+dragon_sects[sect_nr][subsect_nr]+\" dragon\"\n",
    "\n",
    "\n",
    "\n",
    "#returns 0 if dragon alignment is incorrect, 1 if correct \n",
    "def generateCorectness(dragonstring):\n",
    "    \n",
    "    splitdragon=dragonstring.split()\n",
    "    \n",
    "    #print(dragon)\n",
    "    \n",
    "    #chaotic evil brass dragon\n",
    "    if splitdragon[1] == \"evil\" and splitdragon[2] in metallic_dragons:\n",
    "        #print(0)\n",
    "        return 0  \n",
    "    \n",
    "    elif splitdragon[1] == \"good\" and splitdragon[2] in chromatic_dragons:\n",
    "        #print(0)\n",
    "        return 0  \n",
    "    \n",
    "    elif splitdragon[0] == \"lawful\" and splitdragon[2] in primal_dragons:\n",
    "        #print(0)\n",
    "        return 0 \n",
    "    \n",
    "    elif splitdragon[0] == \"chaotic\" and splitdragon[2] in outer_dragons:\n",
    "        #print(0)\n",
    "        return 0 \n",
    "    \n",
    "    else:\n",
    "        #print(1)\n",
    "        return 1\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "#FUNCTION TO ACTUALLY GENERATE AN ARRAY OF DRAGONS\n",
    "def generateArrays(size,generated_dragons,correctness):\n",
    "\n",
    "    for i in range(size):    \n",
    "\n",
    "        tempdragon=generateDragon()\n",
    "\n",
    "        tempcorrect=generateCorectness(tempdragon)\n",
    "\n",
    "        #print(mydragon,tempcorrect)\n",
    "\n",
    "        generated_dragons+=[tempdragon]\n",
    "        correctness+=[tempcorrect]\n",
    "\n",
    "        \n",
    "#GENERATE A TEST SET\n",
    "#testing_data=[]\n",
    "#testing_correctness=[]\n",
    "\n",
    "\n",
    "#generateArrays(100000,test_data,test_correctness)       \n",
    "    \n",
    "#for i in range(len(train_data)):\n",
    "    #print(train_data[i],train_correctness[i])\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39861 60139\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#GENERATE DATA SETS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_size=100000\n",
    "train_data=[]\n",
    "train_correctness=[]\n",
    "\n",
    "test_size=100\n",
    "test_data=[]\n",
    "test_correctness=[]\n",
    "\n",
    "\n",
    "\n",
    "generateArrays(train_size,train_data,train_correctness)\n",
    "generateArrays(test_size,test_data,test_correctness)\n",
    "\n",
    "#for t in range(train_size):\n",
    "    #print(train_data[t],train_correctness[t])\n",
    "#print(\"DONE\")\n",
    "\n",
    "for t in range(test_size):\n",
    "    print(test_data[t],test_correctness[t])\n",
    "\n",
    "print(train_correctness.count(0),train_correctness.count(1))\n",
    "plt.plot([train_correctness.count(0),train_correctness.count(1)],'ro')\n",
    "plt.axis([-1,2,0,train_size])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "labels = \"misaligned dragons\",\"aligned dragons\"\n",
    "sizes = train_correctness.count(0),train_correctness.count(1)\n",
    "colors = 'yellow','aquamarine'\n",
    "explode=(0.1,0)\n",
    "plt.pie(sizes,explode=explode, labels=labels,colors=colors,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING STUFF\n",
    "import tensorflow as ts\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD,RMSprop,Adam \n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#MAGIC NUMBERS\n",
    "nr_neurons_in_first_layer=100\n",
    "nr_neurons_in_second_layer=10\n",
    "nr_classes=2\n",
    "optimizer=Adam()\n",
    "my_batch_size=100\n",
    "my_epochs=500\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  6 12  1]\n",
      " [ 5  3 18  1]\n",
      " [ 2  6 22  1]\n",
      " ...\n",
      " [ 2  2 13  1]\n",
      " [ 5  2 25  1]\n",
      " [ 2  6  7  1]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#FITTIN DATA\n",
    "#tokenizing strings\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_data)\n",
    "index_list = tk.texts_to_sequences(train_data)\n",
    "train_data = pad_sequences(index_list)#x_train = pad_sequences(index_list, maxlen=maxlen)\n",
    "\n",
    "tk.fit_on_texts(test_data)\n",
    "index_list = tk.texts_to_sequences(test_data)\n",
    "test_data = pad_sequences(index_list)#x_train = pad_sequences(index_list, maxlen=maxlen)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "train_correctness=np_utils.to_categorical(train_correctness, nr_classes)\n",
    "\n",
    "test_correctness=np_utils.to_categorical(test_correctness, nr_classes)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data)\n",
    "print(test_correctness)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 1,532\n",
      "Trainable params: 1,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BULIDING A MODEL\n",
    "model=Sequential()\n",
    "model.add(Dense(nr_neurons_in_first_layer, input_shape=(4,), activation='relu' ))\n",
    "model.add(Dense(nr_neurons_in_second_layer, activation='relu'))\n",
    "model.add(Dense(nr_classes, activation='softmax' ))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#COMPILING MODEL\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3466 - acc: 0.9740 - val_loss: 0.3486 - val_acc: 0.9756\n",
      "Epoch 2/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3540 - acc: 0.9714 - val_loss: 0.5267 - val_acc: 0.9313\n",
      "Epoch 3/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3650 - acc: 0.9694 - val_loss: 0.3437 - val_acc: 0.9756\n",
      "Epoch 4/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3779 - acc: 0.9658 - val_loss: 0.3408 - val_acc: 0.9756\n",
      "Epoch 5/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3520 - acc: 0.9717 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 6/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3485 - acc: 0.9730 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 7/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3954 - acc: 0.9630 - val_loss: 0.3418 - val_acc: 0.9756\n",
      "Epoch 8/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3478 - acc: 0.9730 - val_loss: 0.3423 - val_acc: 0.9756\n",
      "Epoch 9/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3459 - acc: 0.9739 - val_loss: 0.3419 - val_acc: 0.9718\n",
      "Epoch 10/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3832 - acc: 0.9640 - val_loss: 0.3403 - val_acc: 0.9756\n",
      "Epoch 11/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3548 - acc: 0.9708 - val_loss: 0.3408 - val_acc: 0.9756\n",
      "Epoch 12/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3646 - acc: 0.9686 - val_loss: 0.3425 - val_acc: 0.9756\n",
      "Epoch 13/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3481 - acc: 0.9729 - val_loss: 0.3418 - val_acc: 0.9719\n",
      "Epoch 14/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3674 - acc: 0.9667 - val_loss: 0.3430 - val_acc: 0.9759\n",
      "Epoch 15/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3457 - acc: 0.9742 - val_loss: 0.3462 - val_acc: 0.9756\n",
      "Epoch 16/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3823 - acc: 0.9663 - val_loss: 0.3404 - val_acc: 0.9756: 0s - loss: 0.3895 - acc: 0.96\n",
      "Epoch 17/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3506 - acc: 0.9723 - val_loss: 0.3444 - val_acc: 0.9756\n",
      "Epoch 18/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3617 - acc: 0.9683 - val_loss: 0.3424 - val_acc: 0.9759\n",
      "Epoch 19/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3523 - acc: 0.9717 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 20/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3616 - acc: 0.9687 - val_loss: 0.3433 - val_acc: 0.9756\n",
      "Epoch 21/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3651 - acc: 0.9697 - val_loss: 1.0551 - val_acc: 0.8553\n",
      "Epoch 22/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3540 - acc: 0.9711 - val_loss: 0.3428 - val_acc: 0.9756\n",
      "Epoch 23/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9739 - val_loss: 0.3416 - val_acc: 0.9756\n",
      "Epoch 24/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3780 - acc: 0.9650 - val_loss: 0.3435 - val_acc: 0.9756\n",
      "Epoch 25/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3474 - acc: 0.9734 - val_loss: 0.3476 - val_acc: 0.9756\n",
      "Epoch 26/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3614 - acc: 0.9683 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 27/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3656 - acc: 0.9688 - val_loss: 0.3433 - val_acc: 0.9756\n",
      "Epoch 28/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3476 - acc: 0.9734 - val_loss: 0.3432 - val_acc: 0.9756\n",
      "Epoch 29/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3939 - acc: 0.9654 - val_loss: 0.4180 - val_acc: 0.9488\n",
      "Epoch 30/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3630 - acc: 0.9697 - val_loss: 0.3425 - val_acc: 0.9756\n",
      "Epoch 31/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3498 - acc: 0.9725 - val_loss: 0.3434 - val_acc: 0.9718\n",
      "Epoch 32/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3577 - acc: 0.9697 - val_loss: 0.3433 - val_acc: 0.9756\n",
      "Epoch 33/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3609 - acc: 0.9694 - val_loss: 0.3407 - val_acc: 0.9756\n",
      "Epoch 34/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3499 - acc: 0.9726 - val_loss: 0.3605 - val_acc: 0.9756\n",
      "Epoch 35/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3659 - acc: 0.9679 - val_loss: 0.3488 - val_acc: 0.9756\n",
      "Epoch 36/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3485 - acc: 0.9727 - val_loss: 0.3402 - val_acc: 0.9756\n",
      "Epoch 37/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3720 - acc: 0.9649 - val_loss: 0.3829 - val_acc: 0.9587\n",
      "Epoch 38/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3481 - acc: 0.9731 - val_loss: 0.3421 - val_acc: 0.9756\n",
      "Epoch 39/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3703 - acc: 0.9670 - val_loss: 0.3909 - val_acc: 0.9351\n",
      "Epoch 40/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3709 - acc: 0.9653 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 41/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3667 - acc: 0.9679 - val_loss: 0.3506 - val_acc: 0.9756\n",
      "Epoch 42/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3457 - acc: 0.9740 - val_loss: 0.3454 - val_acc: 0.9756\n",
      "Epoch 43/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3722 - acc: 0.9658 - val_loss: 0.3408 - val_acc: 0.9756\n",
      "Epoch 44/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3440 - acc: 0.9745 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 45/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3555 - acc: 0.9700 - val_loss: 0.3447 - val_acc: 0.9718\n",
      "Epoch 46/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3535 - acc: 0.9718 - val_loss: 0.3398 - val_acc: 0.9756\n",
      "Epoch 47/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4023 - acc: 0.9620 - val_loss: 0.6799 - val_acc: 0.9224\n",
      "Epoch 48/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6157 - acc: 0.9568 - val_loss: 0.6168 - val_acc: 0.9585\n",
      "Epoch 49/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6277 - acc: 0.9531 - val_loss: 0.6181 - val_acc: 0.9585\n",
      "Epoch 50/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.6179 - acc: 0.9563 - val_loss: 0.6430 - val_acc: 0.9546\n",
      "Epoch 51/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6552 - acc: 0.9481 - val_loss: 0.6162 - val_acc: 0.9585\n",
      "Epoch 52/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6195 - acc: 0.9554 - val_loss: 0.6475 - val_acc: 0.9498\n",
      "Epoch 53/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6253 - acc: 0.9540 - val_loss: 0.6296 - val_acc: 0.9585\n",
      "Epoch 54/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4649 - acc: 0.9615 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 55/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3459 - acc: 0.9741 - val_loss: 0.3398 - val_acc: 0.9756\n",
      "Epoch 56/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3569 - acc: 0.9709 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 57/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3745 - acc: 0.9669 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 58/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3966 - acc: 0.9653 - val_loss: 0.3568 - val_acc: 0.9683\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3449 - acc: 0.9743 - val_loss: 0.3405 - val_acc: 0.9759\n",
      "Epoch 60/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9737 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 61/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3669 - acc: 0.9665 - val_loss: 0.3422 - val_acc: 0.9719\n",
      "Epoch 62/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3516 - acc: 0.9711 - val_loss: 0.3439 - val_acc: 0.9756\n",
      "Epoch 63/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3537 - acc: 0.9704 - val_loss: 0.3739 - val_acc: 0.9559\n",
      "Epoch 64/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4023 - acc: 0.9646 - val_loss: 0.3421 - val_acc: 0.9756\n",
      "Epoch 65/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3440 - acc: 0.9744 - val_loss: 0.3440 - val_acc: 0.9756\n",
      "Epoch 66/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3492 - acc: 0.9729 - val_loss: 0.3575 - val_acc: 0.9630\n",
      "Epoch 67/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3693 - acc: 0.9667 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 68/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3728 - acc: 0.9674 - val_loss: 0.3439 - val_acc: 0.9756\n",
      "Epoch 69/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3449 - acc: 0.9740 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 70/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3532 - acc: 0.9712 - val_loss: 0.3407 - val_acc: 0.9759\n",
      "Epoch 71/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3927 - acc: 0.9654 - val_loss: 0.3480 - val_acc: 0.9718\n",
      "Epoch 72/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3529 - acc: 0.9719 - val_loss: 0.3465 - val_acc: 0.9756\n",
      "Epoch 73/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3556 - acc: 0.9701 - val_loss: 0.3670 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3781 - acc: 0.9657 - val_loss: 0.3420 - val_acc: 0.9756\n",
      "Epoch 75/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3462 - acc: 0.9740 - val_loss: 0.3480 - val_acc: 0.9718\n",
      "Epoch 76/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4317 - acc: 0.9623 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 77/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3756 - acc: 0.9673 - val_loss: 0.3484 - val_acc: 0.9714\n",
      "Epoch 78/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3447 - acc: 0.9741 - val_loss: 0.3477 - val_acc: 0.9718\n",
      "Epoch 79/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3460 - acc: 0.9737 - val_loss: 0.3461 - val_acc: 0.9756\n",
      "Epoch 80/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3699 - acc: 0.9682 - val_loss: 0.3434 - val_acc: 0.9756\n",
      "Epoch 81/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3670 - acc: 0.9675 - val_loss: 0.3488 - val_acc: 0.9718\n",
      "Epoch 82/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3471 - acc: 0.9727 - val_loss: 0.3402 - val_acc: 0.9756A: 0s - loss: 0.3459 - acc: 0.97\n",
      "Epoch 83/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3449 - acc: 0.9742 - val_loss: 0.3397 - val_acc: 0.9756\n",
      "Epoch 84/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3776 - acc: 0.9668 - val_loss: 0.3424 - val_acc: 0.9718\n",
      "Epoch 85/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3469 - acc: 0.9735 - val_loss: 0.3425 - val_acc: 0.9759\n",
      "Epoch 86/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4135 - acc: 0.9620 - val_loss: 0.3419 - val_acc: 0.9756\n",
      "Epoch 87/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3464 - acc: 0.9734 - val_loss: 0.3437 - val_acc: 0.9756\n",
      "Epoch 88/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3533 - acc: 0.9707 - val_loss: 0.3398 - val_acc: 0.9756\n",
      "Epoch 89/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3560 - acc: 0.9707 - val_loss: 0.3428 - val_acc: 0.9756\n",
      "Epoch 90/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3507 - acc: 0.9720 - val_loss: 0.3437 - val_acc: 0.9756\n",
      "Epoch 91/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3917 - acc: 0.9654 - val_loss: 0.3405 - val_acc: 0.9719\n",
      "Epoch 92/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3606 - acc: 0.9695 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 93/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3455 - acc: 0.9740 - val_loss: 0.3418 - val_acc: 0.9759\n",
      "Epoch 94/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3830 - acc: 0.9649 - val_loss: 0.3443 - val_acc: 0.9721\n",
      "Epoch 95/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3496 - acc: 0.9729 - val_loss: 0.3400 - val_acc: 0.9756\n",
      "Epoch 96/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3706 - acc: 0.9662 - val_loss: 0.3416 - val_acc: 0.9759\n",
      "Epoch 97/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3459 - acc: 0.9736 - val_loss: 0.3441 - val_acc: 0.9756\n",
      "Epoch 98/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3752 - acc: 0.9658 - val_loss: 0.3503 - val_acc: 0.9756\n",
      "Epoch 99/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3458 - acc: 0.9740 - val_loss: 0.3543 - val_acc: 0.9677\n",
      "Epoch 100/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3483 - acc: 0.9733 - val_loss: 1.0811 - val_acc: 0.8396\n",
      "Epoch 101/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3697 - acc: 0.9667 - val_loss: 0.3404 - val_acc: 0.9719\n",
      "Epoch 102/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3475 - acc: 0.9730 - val_loss: 0.3551 - val_acc: 0.9756\n",
      "Epoch 103/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4596 - acc: 0.9567 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 104/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3441 - acc: 0.9743 - val_loss: 0.3408 - val_acc: 0.9718\n",
      "Epoch 105/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3474 - acc: 0.9731 - val_loss: 0.3445 - val_acc: 0.9718\n",
      "Epoch 106/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3467 - acc: 0.9737 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 107/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4621 - acc: 0.9603 - val_loss: 0.4723 - val_acc: 0.9678\n",
      "Epoch 108/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4729 - acc: 0.9653 - val_loss: 0.4683 - val_acc: 0.9678\n",
      "Epoch 109/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4859 - acc: 0.9605 - val_loss: 0.4628 - val_acc: 0.9645\n",
      "Epoch 110/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4768 - acc: 0.9654 - val_loss: 0.4580 - val_acc: 0.9683\n",
      "Epoch 111/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4110 - acc: 0.9663 - val_loss: 0.3564 - val_acc: 0.9714\n",
      "Epoch 112/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3605 - acc: 0.9689 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 113/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3457 - acc: 0.9735 - val_loss: 0.3431 - val_acc: 0.9756\n",
      "Epoch 114/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3500 - acc: 0.9723 - val_loss: 0.3403 - val_acc: 0.9756 0s - loss: 0.3559 - acc: 0.9\n",
      "Epoch 115/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3560 - acc: 0.9708 - val_loss: 0.3477 - val_acc: 0.9756\n",
      "Epoch 116/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3563 - acc: 0.9709 - val_loss: 0.3501 - val_acc: 0.9718\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3520 - acc: 0.9719 - val_loss: 0.4112 - val_acc: 0.9471\n",
      "Epoch 118/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3629 - acc: 0.9695 - val_loss: 0.3392 - val_acc: 0.9756\n",
      "Epoch 119/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3805 - acc: 0.9649 - val_loss: 0.3392 - val_acc: 0.9756\n",
      "Epoch 120/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3457 - acc: 0.9738 - val_loss: 0.3458 - val_acc: 0.9756\n",
      "Epoch 121/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3496 - acc: 0.9727 - val_loss: 0.3575 - val_acc: 0.9682\n",
      "Epoch 122/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3767 - acc: 0.9663 - val_loss: 0.3412 - val_acc: 0.9756\n",
      "Epoch 123/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3461 - acc: 0.9737 - val_loss: 0.3442 - val_acc: 0.9718\n",
      "Epoch 124/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3905 - acc: 0.9654 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 125/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3450 - acc: 0.9741 - val_loss: 0.3460 - val_acc: 0.9756\n",
      "Epoch 126/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3852 - acc: 0.9626 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 127/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3458 - acc: 0.9737 - val_loss: 0.3494 - val_acc: 0.9756\n",
      "Epoch 128/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3544 - acc: 0.9708 - val_loss: 0.3536 - val_acc: 0.9718\n",
      "Epoch 129/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3471 - acc: 0.9736 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 130/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3748 - acc: 0.9649 - val_loss: 0.3403 - val_acc: 0.9719\n",
      "Epoch 131/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3476 - acc: 0.9731 - val_loss: 0.3496 - val_acc: 0.9756\n",
      "Epoch 132/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4199 - acc: 0.9610 - val_loss: 0.3424 - val_acc: 0.9756\n",
      "Epoch 133/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3439 - acc: 0.9744 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 134/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3499 - acc: 0.9721 - val_loss: 0.3394 - val_acc: 0.9756\n",
      "Epoch 135/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3532 - acc: 0.9717 - val_loss: 0.5554 - val_acc: 0.8967\n",
      "Epoch 136/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3777 - acc: 0.9657 - val_loss: 0.3642 - val_acc: 0.9571\n",
      "Epoch 137/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3457 - acc: 0.9735 - val_loss: 0.3392 - val_acc: 0.9756A: 0s - loss: 0.3595 - acc: 0.97 - ETA: 0s - loss: 0.3514 - acc: 0\n",
      "Epoch 138/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3705 - acc: 0.9684 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 139/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3461 - acc: 0.9735 - val_loss: 0.3475 - val_acc: 0.9718\n",
      "Epoch 140/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4673 - acc: 0.9604 - val_loss: 0.4640 - val_acc: 0.9679\n",
      "Epoch 141/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4705 - acc: 0.9661 - val_loss: 0.4652 - val_acc: 0.9679\n",
      "Epoch 142/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4822 - acc: 0.9622 - val_loss: 0.4711 - val_acc: 0.9679\n",
      "Epoch 143/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4930 - acc: 0.9595 - val_loss: 0.4632 - val_acc: 0.9679\n",
      "Epoch 144/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4961 - acc: 0.9591 - val_loss: 0.4676 - val_acc: 0.9641\n",
      "Epoch 145/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4698 - acc: 0.9666 - val_loss: 0.4702 - val_acc: 0.9641\n",
      "Epoch 146/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.5342 - acc: 0.9530 - val_loss: 0.3398 - val_acc: 0.9756\n",
      "Epoch 147/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3431 - acc: 0.9745 - val_loss: 0.3397 - val_acc: 0.9756\n",
      "Epoch 148/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3584 - acc: 0.9699 - val_loss: 1.2635 - val_acc: 0.8329\n",
      "Epoch 149/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3501 - acc: 0.9726 - val_loss: 0.3435 - val_acc: 0.9756\n",
      "Epoch 150/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3713 - acc: 0.9680 - val_loss: 0.3469 - val_acc: 0.9756\n",
      "Epoch 151/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3530 - acc: 0.9709 - val_loss: 0.3530 - val_acc: 0.9759\n",
      "Epoch 152/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3487 - acc: 0.9726 - val_loss: 0.3562 - val_acc: 0.9719 0s - loss: 0.3488 - acc: 0.\n",
      "Epoch 153/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3625 - acc: 0.9700 - val_loss: 0.3423 - val_acc: 0.9756\n",
      "Epoch 154/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3611 - acc: 0.9692 - val_loss: 0.4899 - val_acc: 0.9146\n",
      "Epoch 155/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3509 - acc: 0.9716 - val_loss: 0.3402 - val_acc: 0.9756\n",
      "Epoch 156/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3463 - acc: 0.9737 - val_loss: 0.3456 - val_acc: 0.9756\n",
      "Epoch 157/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3817 - acc: 0.9653 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 158/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3444 - acc: 0.9739 - val_loss: 0.3501 - val_acc: 0.9718\n",
      "Epoch 159/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3485 - acc: 0.9723 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 160/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3653 - acc: 0.9669 - val_loss: 0.3443 - val_acc: 0.9718A: 0s - loss: 0.3657 - acc: 0.96\n",
      "Epoch 161/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3441 - acc: 0.9744 - val_loss: 0.3391 - val_acc: 0.9756\n",
      "Epoch 162/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3905 - acc: 0.9658 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 163/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3475 - acc: 0.9729 - val_loss: 0.3531 - val_acc: 0.9681\n",
      "Epoch 164/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4264 - acc: 0.9605 - val_loss: 0.4702 - val_acc: 0.9604\n",
      "Epoch 165/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4758 - acc: 0.9656 - val_loss: 0.4568 - val_acc: 0.9683\n",
      "Epoch 166/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4819 - acc: 0.9637 - val_loss: 0.4977 - val_acc: 0.9565\n",
      "Epoch 167/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3803 - acc: 0.9682 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 168/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3831 - acc: 0.9666 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 169/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3440 - acc: 0.9744 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 170/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3912 - acc: 0.9646 - val_loss: 0.3506 - val_acc: 0.9718\n",
      "Epoch 171/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3521 - acc: 0.9710 - val_loss: 0.3433 - val_acc: 0.9759\n",
      "Epoch 172/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3553 - acc: 0.9699 - val_loss: 0.3415 - val_acc: 0.9756\n",
      "Epoch 173/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9734 - val_loss: 0.3509 - val_acc: 0.9677\n",
      "Epoch 174/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3911 - acc: 0.9631 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3457 - acc: 0.9734 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 176/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3540 - acc: 0.9707 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 177/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3470 - acc: 0.9733 - val_loss: 0.3440 - val_acc: 0.9756\n",
      "Epoch 178/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3665 - acc: 0.9683 - val_loss: 0.3437 - val_acc: 0.9718\n",
      "Epoch 179/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3519 - acc: 0.9715 - val_loss: 0.3416 - val_acc: 0.9756\n",
      "Epoch 180/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3679 - acc: 0.9686 - val_loss: 0.3440 - val_acc: 0.9756\n",
      "Epoch 181/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3475 - acc: 0.9728 - val_loss: 0.3417 - val_acc: 0.9718\n",
      "Epoch 182/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3930 - acc: 0.9631 - val_loss: 0.3480 - val_acc: 0.9630\n",
      "Epoch 183/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3442 - acc: 0.9740 - val_loss: 0.3431 - val_acc: 0.9718\n",
      "Epoch 184/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3500 - acc: 0.9723 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 185/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3790 - acc: 0.9659 - val_loss: 0.3403 - val_acc: 0.9719\n",
      "Epoch 186/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3446 - acc: 0.9742 - val_loss: 0.3396 - val_acc: 0.9756\n",
      "Epoch 187/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3654 - acc: 0.9679 - val_loss: 0.4084 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3467 - acc: 0.9732 - val_loss: 0.3460 - val_acc: 0.9718\n",
      "Epoch 189/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3661 - acc: 0.9676 - val_loss: 0.3415 - val_acc: 0.9759TA: 0s - loss: 0.3673 - acc: 0.967\n",
      "Epoch 190/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3571 - acc: 0.9697 - val_loss: 0.3412 - val_acc: 0.9756\n",
      "Epoch 191/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3441 - acc: 0.9742 - val_loss: 0.3405 - val_acc: 0.9718\n",
      "Epoch 192/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3693 - acc: 0.9673 - val_loss: 0.3415 - val_acc: 0.9718\n",
      "Epoch 193/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3469 - acc: 0.9729 - val_loss: 0.4055 - val_acc: 0.9451\n",
      "Epoch 194/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3497 - acc: 0.9724 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 195/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3743 - acc: 0.9680 - val_loss: 0.3394 - val_acc: 0.9756\n",
      "Epoch 196/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3451 - acc: 0.9740 - val_loss: 0.3453 - val_acc: 0.9719\n",
      "Epoch 197/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3579 - acc: 0.9701 - val_loss: 0.3425 - val_acc: 0.9756\n",
      "Epoch 198/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3567 - acc: 0.9701 - val_loss: 0.4476 - val_acc: 0.9229\n",
      "Epoch 199/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3473 - acc: 0.9731 - val_loss: 0.3580 - val_acc: 0.9756\n",
      "Epoch 200/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3504 - acc: 0.9714 - val_loss: 0.3470 - val_acc: 0.9756\n",
      "Epoch 201/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3862 - acc: 0.9654 - val_loss: 0.3400 - val_acc: 0.9756\n",
      "Epoch 202/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3485 - acc: 0.9729 - val_loss: 0.3607 - val_acc: 0.9585\n",
      "Epoch 203/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3471 - acc: 0.9732 - val_loss: 0.3392 - val_acc: 0.9756\n",
      "Epoch 204/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3773 - acc: 0.9658 - val_loss: 0.3443 - val_acc: 0.9756\n",
      "Epoch 205/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3452 - acc: 0.9739 - val_loss: 0.3456 - val_acc: 0.9718\n",
      "Epoch 206/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3575 - acc: 0.9702 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 207/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3732 - acc: 0.9673 - val_loss: 0.3412 - val_acc: 0.9718\n",
      "Epoch 208/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3434 - acc: 0.9743 - val_loss: 0.3409 - val_acc: 0.9718\n",
      "Epoch 209/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3612 - acc: 0.9691 - val_loss: 0.3423 - val_acc: 0.9718\n",
      "Epoch 210/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3499 - acc: 0.9722 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 211/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3459 - acc: 0.9735 - val_loss: 0.3961 - val_acc: 0.9433\n",
      "Epoch 212/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3592 - acc: 0.9690 - val_loss: 0.3400 - val_acc: 0.9756\n",
      "Epoch 213/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 1.1605 - acc: 0.9195 - val_loss: 1.3210 - val_acc: 0.9154\n",
      "Epoch 214/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.9889 - acc: 0.9279 - val_loss: 0.3432 - val_acc: 0.9759\n",
      "Epoch 215/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3463 - acc: 0.9736 - val_loss: 0.3398 - val_acc: 0.9759\n",
      "Epoch 216/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3463 - acc: 0.9735 - val_loss: 0.3414 - val_acc: 0.9719\n",
      "Epoch 217/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3640 - acc: 0.9674 - val_loss: 0.3387 - val_acc: 0.9756\n",
      "Epoch 218/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3584 - acc: 0.9703 - val_loss: 0.3413 - val_acc: 0.9756\n",
      "Epoch 219/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3459 - acc: 0.9735 - val_loss: 0.3802 - val_acc: 0.9587\n",
      "Epoch 220/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3893 - acc: 0.9648 - val_loss: 0.3396 - val_acc: 0.9756\n",
      "Epoch 221/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3453 - acc: 0.9738 - val_loss: 0.3480 - val_acc: 0.9713\n",
      "Epoch 222/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9734 - val_loss: 0.3388 - val_acc: 0.9756\n",
      "Epoch 223/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3704 - acc: 0.9674 - val_loss: 0.3394 - val_acc: 0.9756\n",
      "Epoch 224/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3522 - acc: 0.9710 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 225/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3630 - acc: 0.9677 - val_loss: 0.3400 - val_acc: 0.9756\n",
      "Epoch 226/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3450 - acc: 0.9740 - val_loss: 0.3408 - val_acc: 0.9756\n",
      "Epoch 227/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3582 - acc: 0.9699 - val_loss: 0.3389 - val_acc: 0.9756\n",
      "Epoch 228/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3491 - acc: 0.9724 - val_loss: 0.3447 - val_acc: 0.9756\n",
      "Epoch 229/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3816 - acc: 0.9664 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 230/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3620 - acc: 0.9688 - val_loss: 0.3392 - val_acc: 0.9756\n",
      "Epoch 231/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3527 - acc: 0.9716 - val_loss: 0.3709 - val_acc: 0.9647\n",
      "Epoch 232/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3454 - acc: 0.9735 - val_loss: 0.3471 - val_acc: 0.9718\n",
      "Epoch 233/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3805 - acc: 0.9673 - val_loss: 0.3412 - val_acc: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3445 - acc: 0.9739 - val_loss: 0.3482 - val_acc: 0.9756\n",
      "Epoch 235/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.6027 - acc: 0.9523 - val_loss: 0.7751 - val_acc: 0.9450\n",
      "Epoch 236/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.8116 - acc: 0.9420 - val_loss: 0.7718 - val_acc: 0.9489\n",
      "Epoch 237/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.8051 - acc: 0.9433 - val_loss: 0.7708 - val_acc: 0.9489\n",
      "Epoch 238/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.7994 - acc: 0.9450 - val_loss: 0.9165 - val_acc: 0.8975\n",
      "Epoch 239/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.8051 - acc: 0.9435 - val_loss: 0.7703 - val_acc: 0.9489\n",
      "Epoch 240/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 1.0288 - acc: 0.9254 - val_loss: 1.0448 - val_acc: 0.9286\n",
      "Epoch 241/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 1.0622 - acc: 0.9295 - val_loss: 1.0348 - val_acc: 0.9324\n",
      "Epoch 242/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.7817 - acc: 0.9441 - val_loss: 0.3402 - val_acc: 0.9756\n",
      "Epoch 243/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4086 - acc: 0.9654 - val_loss: 0.4639 - val_acc: 0.9641\n",
      "Epoch 244/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4783 - acc: 0.9637 - val_loss: 0.4819 - val_acc: 0.9529\n",
      "Epoch 245/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3839 - acc: 0.9657 - val_loss: 0.3412 - val_acc: 0.9719\n",
      "Epoch 246/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3615 - acc: 0.9682 - val_loss: 0.3415 - val_acc: 0.9759\n",
      "Epoch 247/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3439 - acc: 0.9745 - val_loss: 0.3445 - val_acc: 0.9718\n",
      "Epoch 248/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3587 - acc: 0.9697 - val_loss: 0.3412 - val_acc: 0.9719\n",
      "Epoch 249/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3561 - acc: 0.9692 - val_loss: 0.3416 - val_acc: 0.9756\n",
      "Epoch 250/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3514 - acc: 0.9717 - val_loss: 0.3545 - val_acc: 0.9683\n",
      "Epoch 251/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3685 - acc: 0.9680 - val_loss: 0.3411 - val_acc: 0.9756\n",
      "Epoch 252/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3546 - acc: 0.9715 - val_loss: 1.2204 - val_acc: 0.7750\n",
      "Epoch 253/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3598 - acc: 0.9707 - val_loss: 0.3443 - val_acc: 0.9756\n",
      "Epoch 254/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3721 - acc: 0.9676 - val_loss: 0.3403 - val_acc: 0.9756\n",
      "Epoch 255/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3461 - acc: 0.9731 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 256/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3643 - acc: 0.9678 - val_loss: 0.3396 - val_acc: 0.9756\n",
      "Epoch 257/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3438 - acc: 0.9741 - val_loss: 0.3432 - val_acc: 0.9756\n",
      "Epoch 258/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3963 - acc: 0.9628 - val_loss: 0.3471 - val_acc: 0.9679\n",
      "Epoch 259/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3469 - acc: 0.9739 - val_loss: 0.3442 - val_acc: 0.9756\n",
      "Epoch 260/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3633 - acc: 0.9699 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 261/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9736 - val_loss: 0.3442 - val_acc: 0.9756\n",
      "Epoch 262/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3551 - acc: 0.9697 - val_loss: 0.3397 - val_acc: 0.9756\n",
      "Epoch 263/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3742 - acc: 0.9667 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 264/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3456 - acc: 0.9737 - val_loss: 0.3602 - val_acc: 0.9634\n",
      "Epoch 265/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3536 - acc: 0.9713 - val_loss: 0.3455 - val_acc: 0.9718\n",
      "Epoch 266/500\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 0.3643 - acc: 0.9685- ETA: 0s - loss: 0.3549 - acc:  - ETA: 0s - loss: 0.3495 - acc: 0.9 - 1s 9us/step - loss: 0.3670 - acc: 0.9676 - val_loss: 0.5942 - val_acc: 0.9133\n",
      "Epoch 267/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3501 - acc: 0.9714 - val_loss: 0.3407 - val_acc: 0.9718\n",
      "Epoch 268/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3604 - acc: 0.9692 - val_loss: 0.3407 - val_acc: 0.9759- loss: 0.3638 - acc: 0.96\n",
      "Epoch 269/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3464 - acc: 0.9732 - val_loss: 0.3459 - val_acc: 0.9756\n",
      "Epoch 270/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4492 - acc: 0.9621 - val_loss: 0.4638 - val_acc: 0.9679\n",
      "Epoch 271/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4719 - acc: 0.9660 - val_loss: 0.4821 - val_acc: 0.9641\n",
      "Epoch 272/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4376 - acc: 0.9656 - val_loss: 0.3439 - val_acc: 0.9756\n",
      "Epoch 273/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3650 - acc: 0.9687 - val_loss: 0.3400 - val_acc: 0.9756\n",
      "Epoch 274/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3983 - acc: 0.9666 - val_loss: 0.4598 - val_acc: 0.9683\n",
      "Epoch 275/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4751 - acc: 0.9660 - val_loss: 0.4836 - val_acc: 0.9557 0s - loss: 0.4781 - acc: 0\n",
      "Epoch 276/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3990 - acc: 0.9669 - val_loss: 0.3438 - val_acc: 0.9719\n",
      "Epoch 277/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3662 - acc: 0.9685 - val_loss: 0.4422 - val_acc: 0.9441\n",
      "Epoch 278/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3521 - acc: 0.9711 - val_loss: 0.3404 - val_acc: 0.9719\n",
      "Epoch 279/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3465 - acc: 0.9732 - val_loss: 0.3445 - val_acc: 0.9718\n",
      "Epoch 280/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3758 - acc: 0.9657 - val_loss: 0.3417 - val_acc: 0.9718\n",
      "Epoch 281/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3445 - acc: 0.9741 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 282/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3665 - acc: 0.9685 - val_loss: 0.3428 - val_acc: 0.9756\n",
      "Epoch 283/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3540 - acc: 0.9698 - val_loss: 0.3391 - val_acc: 0.9719\n",
      "Epoch 284/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3494 - acc: 0.9721 - val_loss: 0.3901 - val_acc: 0.9606\n",
      "Epoch 285/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3543 - acc: 0.9705 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 286/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3545 - acc: 0.9703 - val_loss: 0.3386 - val_acc: 0.9756\n",
      "Epoch 287/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3442 - acc: 0.9744 - val_loss: 0.3388 - val_acc: 0.9756\n",
      "Epoch 288/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4798 - acc: 0.9589 - val_loss: 0.4647 - val_acc: 0.9641\n",
      "Epoch 289/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4713 - acc: 0.9656 - val_loss: 0.4656 - val_acc: 0.9641\n",
      "Epoch 290/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4843 - acc: 0.9617 - val_loss: 0.4661 - val_acc: 0.9678\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4776 - acc: 0.9630 - val_loss: 0.4805 - val_acc: 0.9640\n",
      "Epoch 292/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4247 - acc: 0.9656 - val_loss: 0.3401 - val_acc: 0.9759\n",
      "Epoch 293/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3584 - acc: 0.9709 - val_loss: 0.5122 - val_acc: 0.9518\n",
      "Epoch 294/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3560 - acc: 0.9702 - val_loss: 0.3439 - val_acc: 0.9718\n",
      "Epoch 295/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3535 - acc: 0.9703 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 296/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3508 - acc: 0.9714 - val_loss: 0.3457 - val_acc: 0.9756\n",
      "Epoch 297/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3695 - acc: 0.9688 - val_loss: 0.3413 - val_acc: 0.9756\n",
      "Epoch 298/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3457 - acc: 0.9736 - val_loss: 0.3472 - val_acc: 0.9718\n",
      "Epoch 299/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4145 - acc: 0.9624 - val_loss: 0.3415 - val_acc: 0.9756\n",
      "Epoch 300/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3436 - acc: 0.9740 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 301/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3442 - acc: 0.9741 - val_loss: 0.3464 - val_acc: 0.9718\n",
      "Epoch 302/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3638 - acc: 0.9683 - val_loss: 0.3501 - val_acc: 0.9630\n",
      "Epoch 303/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3595 - acc: 0.9691 - val_loss: 0.3387 - val_acc: 0.9756\n",
      "Epoch 304/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3448 - acc: 0.9739 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 305/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3516 - acc: 0.9718 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 306/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3516 - acc: 0.9720 - val_loss: 0.8277 - val_acc: 0.8573\n",
      "Epoch 307/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3689 - acc: 0.9690 - val_loss: 0.3501 - val_acc: 0.9718\n",
      "Epoch 308/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3450 - acc: 0.9739 - val_loss: 0.3418 - val_acc: 0.9756\n",
      "Epoch 309/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3737 - acc: 0.9668 - val_loss: 0.3406 - val_acc: 0.9756\n",
      "Epoch 310/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3686 - acc: 0.9692 - val_loss: 0.3399 - val_acc: 0.9756\n",
      "Epoch 311/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3460 - acc: 0.9734 - val_loss: 0.3402 - val_acc: 0.9756\n",
      "Epoch 312/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3436 - acc: 0.9742 - val_loss: 0.3385 - val_acc: 0.9756\n",
      "Epoch 313/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3793 - acc: 0.9668 - val_loss: 0.3412 - val_acc: 0.9756\n",
      "Epoch 314/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3510 - acc: 0.9718 - val_loss: 0.3384 - val_acc: 0.9756\n",
      "Epoch 315/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3450 - acc: 0.9736 - val_loss: 0.3386 - val_acc: 0.9756\n",
      "Epoch 316/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3569 - acc: 0.9702 - val_loss: 0.3445 - val_acc: 0.9718\n",
      "Epoch 317/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3449 - acc: 0.9738 - val_loss: 0.3421 - val_acc: 0.9718\n",
      "Epoch 318/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3669 - acc: 0.9696 - val_loss: 0.3384 - val_acc: 0.9756\n",
      "Epoch 319/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3729 - acc: 0.9670 - val_loss: 0.3509 - val_acc: 0.9756\n",
      "Epoch 320/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3436 - acc: 0.9740 - val_loss: 0.3542 - val_acc: 0.9756\n",
      "Epoch 321/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3503 - acc: 0.9726 - val_loss: 0.3641 - val_acc: 0.9715\n",
      "Epoch 322/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3491 - acc: 0.9725 - val_loss: 0.3389 - val_acc: 0.9756\n",
      "Epoch 323/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3452 - acc: 0.9741 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 324/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.5723 - acc: 0.9509 - val_loss: 0.5800 - val_acc: 0.9606\n",
      "Epoch 325/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.6001 - acc: 0.9583 - val_loss: 0.5810 - val_acc: 0.9606\n",
      "Epoch 326/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.5681 - acc: 0.9568 - val_loss: 0.4711 - val_acc: 0.9641\n",
      "Epoch 327/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4716 - acc: 0.9656 - val_loss: 0.4637 - val_acc: 0.9679\n",
      "Epoch 328/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4813 - acc: 0.9626 - val_loss: 0.4644 - val_acc: 0.9679\n",
      "Epoch 329/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4976 - acc: 0.9600 - val_loss: 0.4630 - val_acc: 0.9679\n",
      "Epoch 330/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4697 - acc: 0.9664 - val_loss: 0.4652 - val_acc: 0.9679\n",
      "Epoch 331/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4986 - acc: 0.9612 - val_loss: 0.4645 - val_acc: 0.9679\n",
      "Epoch 332/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4898 - acc: 0.9610 - val_loss: 0.4630 - val_acc: 0.9679\n",
      "Epoch 333/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4695 - acc: 0.9665 - val_loss: 0.4627 - val_acc: 0.9679\n",
      "Epoch 334/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4750 - acc: 0.9648 - val_loss: 0.4623 - val_acc: 0.9679\n",
      "Epoch 335/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4573 - acc: 0.9609 - val_loss: 0.3459 - val_acc: 0.9756\n",
      "Epoch 336/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3816 - acc: 0.9653 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 337/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3441 - acc: 0.9745 - val_loss: 0.3411 - val_acc: 0.9718\n",
      "Epoch 338/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3701 - acc: 0.9676 - val_loss: 0.3432 - val_acc: 0.9756\n",
      "Epoch 339/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3436 - acc: 0.9740 - val_loss: 0.3387 - val_acc: 0.9756\n",
      "Epoch 340/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3542 - acc: 0.9710 - val_loss: 0.3384 - val_acc: 0.9756\n",
      "Epoch 341/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3496 - acc: 0.9720 - val_loss: 0.3419 - val_acc: 0.9718\n",
      "Epoch 342/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3541 - acc: 0.9715 - val_loss: 2.3732 - val_acc: 0.7369\n",
      "Epoch 343/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3712 - acc: 0.9690 - val_loss: 0.3384 - val_acc: 0.9756\n",
      "Epoch 344/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3598 - acc: 0.9706 - val_loss: 0.3430 - val_acc: 0.9756\n",
      "Epoch 345/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3520 - acc: 0.9717 - val_loss: 0.3538 - val_acc: 0.9722\n",
      "Epoch 346/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3492 - acc: 0.9723 - val_loss: 0.3503 - val_acc: 0.9718\n",
      "Epoch 347/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3574 - acc: 0.9702 - val_loss: 0.4902 - val_acc: 0.9236\n",
      "Epoch 348/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3451 - acc: 0.9738 - val_loss: 0.3442 - val_acc: 0.9718\n",
      "Epoch 349/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4050 - acc: 0.9612 - val_loss: 0.3386 - val_acc: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3437 - acc: 0.9743 - val_loss: 0.3396 - val_acc: 0.9756\n",
      "Epoch 351/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3465 - acc: 0.9734 - val_loss: 0.3596 - val_acc: 0.9630\n",
      "Epoch 352/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3575 - acc: 0.9706 - val_loss: 0.3412 - val_acc: 0.9718\n",
      "Epoch 353/500\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 0.3612 - acc: 0.969 - 1s 9us/step - loss: 0.3599 - acc: 0.9700 - val_loss: 0.3389 - val_acc: 0.9719\n",
      "Epoch 354/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3740 - acc: 0.9674 - val_loss: 0.3404 - val_acc: 0.9718\n",
      "Epoch 355/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3429 - acc: 0.9745 - val_loss: 0.3408 - val_acc: 0.9718\n",
      "Epoch 356/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4092 - acc: 0.9631 - val_loss: 0.3386 - val_acc: 0.9756\n",
      "Epoch 357/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3445 - acc: 0.9739 - val_loss: 0.3490 - val_acc: 0.9718\n",
      "Epoch 358/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3500 - acc: 0.9718 - val_loss: 0.3464 - val_acc: 0.9756\n",
      "Epoch 359/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3693 - acc: 0.9673 - val_loss: 0.3406 - val_acc: 0.9719\n",
      "Epoch 360/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3481 - acc: 0.9726 - val_loss: 0.3395 - val_acc: 0.97560s - loss: 0.3449 - acc: 0.97\n",
      "Epoch 361/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3578 - acc: 0.9692 - val_loss: 0.3405 - val_acc: 0.9756\n",
      "Epoch 362/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3532 - acc: 0.9712 - val_loss: 0.3468 - val_acc: 0.9718\n",
      "Epoch 363/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3480 - acc: 0.9726 - val_loss: 0.3552 - val_acc: 0.9680\n",
      "Epoch 364/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3933 - acc: 0.9658 - val_loss: 0.4700 - val_acc: 0.9679\n",
      "Epoch 365/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4701 - acc: 0.9662 - val_loss: 0.4624 - val_acc: 0.9679\n",
      "Epoch 366/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4696 - acc: 0.9664 - val_loss: 0.4645 - val_acc: 0.9679\n",
      "Epoch 367/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4835 - acc: 0.9618 - val_loss: 0.4667 - val_acc: 0.9641A: 0s - loss: 0.4852 - acc: 0.96\n",
      "Epoch 368/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4858 - acc: 0.9621 - val_loss: 0.4691 - val_acc: 0.9641\n",
      "Epoch 369/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4711 - acc: 0.9659 - val_loss: 0.4647 - val_acc: 0.9679\n",
      "Epoch 370/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4958 - acc: 0.9579 - val_loss: 0.4646 - val_acc: 0.9641\n",
      "Epoch 371/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4695 - acc: 0.9665 - val_loss: 0.4683 - val_acc: 0.9641\n",
      "Epoch 372/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4783 - acc: 0.9608 - val_loss: 0.3437 - val_acc: 0.9714\n",
      "Epoch 373/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3446 - acc: 0.9736 - val_loss: 0.3437 - val_acc: 0.9718\n",
      "Epoch 374/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3726 - acc: 0.9673 - val_loss: 0.3390 - val_acc: 0.9756\n",
      "Epoch 375/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3449 - acc: 0.9739 - val_loss: 0.3423 - val_acc: 0.9756\n",
      "Epoch 376/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3513 - acc: 0.9714 - val_loss: 0.3385 - val_acc: 0.9756\n",
      "Epoch 377/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3652 - acc: 0.9677 - val_loss: 0.3989 - val_acc: 0.9640\n",
      "Epoch 378/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3450 - acc: 0.9737 - val_loss: 0.3396 - val_acc: 0.9719\n",
      "Epoch 379/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3490 - acc: 0.9728 - val_loss: 0.8819 - val_acc: 0.8910\n",
      "Epoch 380/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3785 - acc: 0.9655 - val_loss: 0.3522 - val_acc: 0.9756\n",
      "Epoch 381/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3436 - acc: 0.9742 - val_loss: 0.3394 - val_acc: 0.9756\n",
      "Epoch 382/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3524 - acc: 0.9716 - val_loss: 0.3438 - val_acc: 0.9756\n",
      "Epoch 383/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3799 - acc: 0.9653 - val_loss: 0.3405 - val_acc: 0.9718\n",
      "Epoch 384/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3504 - acc: 0.9719 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 385/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.3433 - acc: 0.9745 - val_loss: 0.3398 - val_acc: 0.9756\n",
      "Epoch 386/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3700 - acc: 0.9667 - val_loss: 0.3489 - val_acc: 0.9718\n",
      "Epoch 387/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3562 - acc: 0.9705 - val_loss: 0.3501 - val_acc: 0.9718\n",
      "Epoch 388/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3453 - acc: 0.9736 - val_loss: 0.3382 - val_acc: 0.9756\n",
      "Epoch 389/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3835 - acc: 0.9636 - val_loss: 0.3445 - val_acc: 0.9756\n",
      "Epoch 390/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3434 - acc: 0.9744 - val_loss: 0.3397 - val_acc: 0.9759\n",
      "Epoch 391/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3476 - acc: 0.9729 - val_loss: 0.3499 - val_acc: 0.9718\n",
      "Epoch 392/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3479 - acc: 0.9729 - val_loss: 0.3420 - val_acc: 0.9756\n",
      "Epoch 393/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3560 - acc: 0.9696 - val_loss: 0.3401 - val_acc: 0.9718\n",
      "Epoch 394/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3594 - acc: 0.9692 - val_loss: 0.3489 - val_acc: 0.9718\n",
      "Epoch 395/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3524 - acc: 0.9708 - val_loss: 0.3460 - val_acc: 0.9668\n",
      "Epoch 396/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.6076 - acc: 0.9548 - val_loss: 0.8391 - val_acc: 0.9446\n",
      "Epoch 397/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.8680 - acc: 0.9413 - val_loss: 0.8410 - val_acc: 0.9446\n",
      "Epoch 398/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8731 - acc: 0.9394 - val_loss: 0.8399 - val_acc: 0.9446\n",
      "Epoch 399/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.8109 - acc: 0.9433 - val_loss: 0.7761 - val_acc: 0.9489\n",
      "Epoch 400/500\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 0.8057 - acc: 0.943 - 1s 9us/step - loss: 0.8043 - acc: 0.9436 - val_loss: 0.7696 - val_acc: 0.9489\n",
      "Epoch 401/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8182 - acc: 0.9399 - val_loss: 0.7762 - val_acc: 0.9450\n",
      "Epoch 402/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7972 - acc: 0.9463 - val_loss: 0.7717 - val_acc: 0.9489\n",
      "Epoch 403/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8224 - acc: 0.9411 - val_loss: 0.7699 - val_acc: 0.9489\n",
      "Epoch 404/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8102 - acc: 0.9416 - val_loss: 0.7851 - val_acc: 0.9412\n",
      "Epoch 405/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7978 - acc: 0.9459 - val_loss: 0.7735 - val_acc: 0.9489\n",
      "Epoch 406/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.9471 - acc: 0.9304 - val_loss: 0.9702 - val_acc: 0.9366: 0s - loss: 0.9307 - acc: 0.\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9838 - acc: 0.9344 - val_loss: 0.9783 - val_acc: 0.9327\n",
      "Epoch 408/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9903 - acc: 0.9261 - val_loss: 0.9238 - val_acc: 0.9291\n",
      "Epoch 409/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9261 - acc: 0.9372 - val_loss: 0.8977 - val_acc: 0.9412\n",
      "Epoch 410/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9343 - acc: 0.9346 - val_loss: 0.8966 - val_acc: 0.9373\n",
      "Epoch 411/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.9292 - acc: 0.9362 - val_loss: 1.4780 - val_acc: 0.8412\n",
      "Epoch 412/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9476 - acc: 0.9321 - val_loss: 0.9015 - val_acc: 0.9373\n",
      "Epoch 413/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9481 - acc: 0.9313 - val_loss: 0.8960 - val_acc: 0.9375\n",
      "Epoch 414/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9244 - acc: 0.9377 - val_loss: 0.8955 - val_acc: 0.9375\n",
      "Epoch 415/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.9241 - acc: 0.9384 - val_loss: 0.8954 - val_acc: 0.9412 0s - loss: 0.9321 - acc: 0.93 - ETA: 0s - loss: 0.9250 - acc: 0.9\n",
      "Epoch 416/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.9353 - acc: 0.9320 - val_loss: 0.8648 - val_acc: 0.9430\n",
      "Epoch 417/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8701 - acc: 0.9405 - val_loss: 0.8650 - val_acc: 0.9430\n",
      "Epoch 418/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.8169 - acc: 0.9411 - val_loss: 0.7659 - val_acc: 0.9381\n",
      "Epoch 419/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7424 - acc: 0.9490 - val_loss: 0.7395 - val_acc: 0.9507\n",
      "Epoch 420/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7470 - acc: 0.9473 - val_loss: 0.7408 - val_acc: 0.9507\n",
      "Epoch 421/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7595 - acc: 0.9428 - val_loss: 0.7407 - val_acc: 0.9507\n",
      "Epoch 422/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7394 - acc: 0.9497 - val_loss: 0.7394 - val_acc: 0.9507\n",
      "Epoch 423/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.7678 - acc: 0.9416 - val_loss: 0.7449 - val_acc: 0.9469\n",
      "Epoch 424/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.7477 - acc: 0.9469 - val_loss: 0.7410 - val_acc: 0.9507\n",
      "Epoch 425/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7409 - acc: 0.9494 - val_loss: 0.7406 - val_acc: 0.9507\n",
      "Epoch 426/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.7620 - acc: 0.9441 - val_loss: 0.7606 - val_acc: 0.9431\n",
      "Epoch 427/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.5701 - acc: 0.9559 - val_loss: 0.4628 - val_acc: 0.9679\n",
      "Epoch 428/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4756 - acc: 0.9644 - val_loss: 0.4662 - val_acc: 0.9679\n",
      "Epoch 429/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.9576 - val_loss: 0.4624 - val_acc: 0.9679\n",
      "Epoch 430/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4700 - acc: 0.9662 - val_loss: 0.4628 - val_acc: 0.9679\n",
      "Epoch 431/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4859 - acc: 0.9619 - val_loss: 0.4625 - val_acc: 0.9679\n",
      "Epoch 432/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.5331 - acc: 0.9548 - val_loss: 0.4661 - val_acc: 0.9679\n",
      "Epoch 433/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4705 - acc: 0.9662 - val_loss: 0.4635 - val_acc: 0.9679\n",
      "Epoch 434/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4749 - acc: 0.9646 - val_loss: 0.4644 - val_acc: 0.9679\n",
      "Epoch 435/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4706 - acc: 0.9662 - val_loss: 0.4802 - val_acc: 0.9641\n",
      "Epoch 436/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.5079 - acc: 0.9580 - val_loss: 0.4640 - val_acc: 0.9679\n",
      "Epoch 437/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4718 - acc: 0.9661 - val_loss: 0.4648 - val_acc: 0.9641 0s - loss: 0.4789 - acc: 0\n",
      "Epoch 438/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.5329 - acc: 0.9547 - val_loss: 0.5615 - val_acc: 0.9408\n",
      "Epoch 439/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4717 - acc: 0.9658 - val_loss: 0.4692 - val_acc: 0.96780s - loss: 0.4671 - acc: 0.\n",
      "Epoch 440/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4691 - acc: 0.9667 - val_loss: 0.4678 - val_acc: 0.9678\n",
      "Epoch 441/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4951 - acc: 0.9586 - val_loss: 0.4724 - val_acc: 0.9678\n",
      "Epoch 442/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4685 - acc: 0.9667 - val_loss: 0.4669 - val_acc: 0.9640\n",
      "Epoch 443/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4790 - acc: 0.9636 - val_loss: 0.4703 - val_acc: 0.9678\n",
      "Epoch 444/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4783 - acc: 0.9591 - val_loss: 0.3460 - val_acc: 0.9718\n",
      "Epoch 445/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3436 - acc: 0.9741 - val_loss: 0.3476 - val_acc: 0.9756\n",
      "Epoch 446/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3460 - acc: 0.9735 - val_loss: 0.3582 - val_acc: 0.9756\n",
      "Epoch 447/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3575 - acc: 0.9698 - val_loss: 0.3386 - val_acc: 0.9756\n",
      "Epoch 448/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4191 - acc: 0.9637 - val_loss: 0.4655 - val_acc: 0.9678\n",
      "Epoch 449/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4677 - acc: 0.9667 - val_loss: 0.4651 - val_acc: 0.9678\n",
      "Epoch 450/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4689 - acc: 0.9666 - val_loss: 0.4711 - val_acc: 0.9640\n",
      "Epoch 451/500\n",
      "80000/80000 [==============================] - 1s 11us/step - loss: 0.5373 - acc: 0.9592 - val_loss: 0.5407 - val_acc: 0.9598\n",
      "Epoch 452/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4809 - acc: 0.9609 - val_loss: 0.3388 - val_acc: 0.9756\n",
      "Epoch 453/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3774 - acc: 0.9662 - val_loss: 0.3470 - val_acc: 0.9714\n",
      "Epoch 454/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3474 - acc: 0.9726 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 455/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3825 - acc: 0.9663 - val_loss: 0.3404 - val_acc: 0.9756 - loss: 0.3855 - acc: 0.96\n",
      "Epoch 456/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3445 - acc: 0.9741 - val_loss: 0.3395 - val_acc: 0.9756\n",
      "Epoch 457/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3620 - acc: 0.9683 - val_loss: 0.4940 - val_acc: 0.9153\n",
      "Epoch 458/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3464 - acc: 0.9729 - val_loss: 0.3456 - val_acc: 0.9668\n",
      "Epoch 459/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3469 - acc: 0.9731 - val_loss: 0.3779 - val_acc: 0.9606\n",
      "Epoch 460/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4044 - acc: 0.9641 - val_loss: 0.4057 - val_acc: 0.9715\n",
      "Epoch 461/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4141 - acc: 0.9697 - val_loss: 0.4054 - val_acc: 0.9715\n",
      "Epoch 462/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4152 - acc: 0.9650 - val_loss: 0.3389 - val_acc: 0.9756\n",
      "Epoch 463/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3431 - acc: 0.9744 - val_loss: 0.3407 - val_acc: 0.9718\n",
      "Epoch 464/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3794 - acc: 0.9660 - val_loss: 0.3396 - val_acc: 0.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3441 - acc: 0.9742 - val_loss: 0.3449 - val_acc: 0.9718\n",
      "Epoch 466/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3713 - acc: 0.9685 - val_loss: 1.2917 - val_acc: 0.8515\n",
      "Epoch 467/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3604 - acc: 0.9706 - val_loss: 0.3397 - val_acc: 0.9756\n",
      "Epoch 468/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3508 - acc: 0.9717 - val_loss: 0.3399 - val_acc: 0.9759\n",
      "Epoch 469/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3562 - acc: 0.9705 - val_loss: 0.3394 - val_acc: 0.9756\n",
      "Epoch 470/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3462 - acc: 0.9731 - val_loss: 0.3409 - val_acc: 0.9756\n",
      "Epoch 471/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3722 - acc: 0.9667 - val_loss: 0.3401 - val_acc: 0.9756\n",
      "Epoch 472/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3451 - acc: 0.9738 - val_loss: 0.3393 - val_acc: 0.9756\n",
      "Epoch 473/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3555 - acc: 0.9701 - val_loss: 0.3403 - val_acc: 0.9756\n",
      "Epoch 474/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3536 - acc: 0.9709 - val_loss: 0.3397 - val_acc: 0.9756\n",
      "Epoch 475/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3603 - acc: 0.9697 - val_loss: 0.3448 - val_acc: 0.9756\n",
      "Epoch 476/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3443 - acc: 0.9741 - val_loss: 0.3434 - val_acc: 0.9756\n",
      "Epoch 477/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3557 - acc: 0.9711 - val_loss: 0.3404 - val_acc: 0.9756\n",
      "Epoch 478/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3511 - acc: 0.9720 - val_loss: 0.3495 - val_acc: 0.9756\n",
      "Epoch 479/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3730 - acc: 0.9659 - val_loss: 0.3393 - val_acc: 0.9756\n",
      "Epoch 480/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3437 - acc: 0.9741 - val_loss: 0.3396 - val_acc: 0.9756\n",
      "Epoch 481/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3517 - acc: 0.9716 - val_loss: 0.3403 - val_acc: 0.9718\n",
      "Epoch 482/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3578 - acc: 0.9703 - val_loss: 0.3391 - val_acc: 0.9756\n",
      "Epoch 483/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4219 - acc: 0.9635 - val_loss: 0.4771 - val_acc: 0.9640\n",
      "Epoch 484/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4741 - acc: 0.9637 - val_loss: 0.4641 - val_acc: 0.9678\n",
      "Epoch 485/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4718 - acc: 0.9652 - val_loss: 0.4639 - val_acc: 0.9678\n",
      "Epoch 486/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4721 - acc: 0.9653 - val_loss: 0.4695 - val_acc: 0.9640\n",
      "Epoch 487/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.4088 - acc: 0.9649 - val_loss: 0.3386 - val_acc: 0.9756\n",
      "Epoch 488/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3443 - acc: 0.9740 - val_loss: 0.3395 - val_acc: 0.9719\n",
      "Epoch 489/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3458 - acc: 0.9739 - val_loss: 0.3508 - val_acc: 0.9756\n",
      "Epoch 490/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3980 - acc: 0.9652 - val_loss: 0.3495 - val_acc: 0.9756\n",
      "Epoch 491/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3434 - acc: 0.9742 - val_loss: 0.3420 - val_acc: 0.9756\n",
      "Epoch 492/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3494 - acc: 0.9721 - val_loss: 0.3403 - val_acc: 0.9756\n",
      "Epoch 493/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3595 - acc: 0.9689 - val_loss: 0.3389 - val_acc: 0.9719\n",
      "Epoch 494/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.3477 - acc: 0.9732 - val_loss: 0.3835 - val_acc: 0.9553\n",
      "Epoch 495/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3454 - acc: 0.9737 - val_loss: 0.3496 - val_acc: 0.9756\n",
      "Epoch 496/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.3457 - acc: 0.9736 - val_loss: 0.3460 - val_acc: 0.9718\n",
      "Epoch 497/500\n",
      "80000/80000 [==============================] - 1s 10us/step - loss: 0.5023 - acc: 0.9582 - val_loss: 0.4647 - val_acc: 0.9641\n",
      "Epoch 498/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4706 - acc: 0.9661 - val_loss: 0.4624 - val_acc: 0.9679\n",
      "Epoch 499/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4734 - acc: 0.9653 - val_loss: 0.8205 - val_acc: 0.8563\n",
      "Epoch 500/500\n",
      "80000/80000 [==============================] - 1s 9us/step - loss: 0.4761 - acc: 0.9647 - val_loss: 0.4678 - val_acc: 0.9679\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_train, y_train_onehot, batch_size=b_size, epochs=epoch, verbose=1, validation_split=0.2)\n",
    "\n",
    "history= model.fit(train_data,train_correctness, batch_size=my_batch_size, epochs=my_epochs, verbose=1, validation_split=0.2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 80us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data,test_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  2.4274305988386913\n",
      "accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \",score[0])\n",
    "print(\"accuracy: \",score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
