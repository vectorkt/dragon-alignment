{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#GENRATING DRAGONS\n",
    "\n",
    "import random\n",
    "from random import randint\n",
    "#print(randint(0, 9)) results in a number from [0,9]\n",
    "\n",
    "#DRAGON SECTS\n",
    "#https://pathfinderwiki.com/wiki/Dragon#Draconic_septs\n",
    "#metalic dragons=Good brass, copper, bronze, silver, and gold\n",
    "#chromatic dragons=Evil \"white\", \"black\", \"green\", \"blue\", \"red\" \n",
    "#Primal dragons=Chaotic brine, cloud, crystal, magma, and umbral\n",
    "#Outer dragons=Lawful lunar, solar, time, void, vortex\n",
    "\n",
    "#good\n",
    "metallic_dragons=[\"brass\", \"copper\", \"bronze\", \"silver\", \"gold\"]\n",
    "\n",
    "#evil\n",
    "chromatic_dragons=[\"white\", \"black\", \"green\", \"blue\", \"red\"]\n",
    "\n",
    "#chaotic\n",
    "primal_dragons=[\"brine\", \"cloud\", \"crystal\", \"magma\", \"umbral\"]\n",
    "\n",
    "#lawful\n",
    "outer_dragons=[\"lunar\", \"solar\", \"time\", \"void\", \"vortex\"]\n",
    "\n",
    "\n",
    "#dragons_sects[type][subtype]\n",
    "dragon_sects =[metallic_dragons,chromatic_dragons,primal_dragons,outer_dragons]\n",
    "\n",
    "#ALIGNMENTS\n",
    "law_chaos=[\"lawful\",\"lawful\",\"neutral\",\"chaotic\",\"chaotic\"]\n",
    "good_evil=[\"good\",\"good\",\"neutral\",\"evil\",\"evil\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#return dragon as a string    \n",
    "def generateDragon():    \n",
    "\n",
    "    sect_nr=randint(0,len(dragon_sects)-1)\n",
    "    \n",
    "    subsect_nr=randint(0,len(dragon_sects[sect_nr])-1)\n",
    "    \n",
    "    lawfulness_nr=randint(0,len(law_chaos)-1)   \n",
    "    \n",
    "    morality_nr=randint(0,len(good_evil)-1)\n",
    "    \n",
    "    return law_chaos[lawfulness_nr]+\" \"+good_evil[morality_nr]+\" \"+dragon_sects[sect_nr][subsect_nr]+\" dragon\"\n",
    "\n",
    "\n",
    "\n",
    "#returns 0 if dragon alignment is incorrect, 1 if correct \n",
    "def generateCorectness(dragonstring):\n",
    "    \n",
    "    splitdragon=dragonstring.split()\n",
    "    \n",
    "    #print(dragon)\n",
    "    \n",
    "    #chaotic evil brass dragon\n",
    "    if splitdragon[1] == \"evil\" and splitdragon[2] in metallic_dragons:\n",
    "        #print(0)\n",
    "        return 0  \n",
    "    \n",
    "    elif splitdragon[1] == \"good\" and splitdragon[2] in chromatic_dragons:\n",
    "        #print(0)\n",
    "        return 0  \n",
    "    \n",
    "    elif splitdragon[0] == \"lawful\" and splitdragon[2] in primal_dragons:\n",
    "        #print(0)\n",
    "        return 0 \n",
    "    \n",
    "    elif splitdragon[0] == \"chaotic\" and splitdragon[2] in outer_dragons:\n",
    "        #print(0)\n",
    "        return 0 \n",
    "    \n",
    "    else:\n",
    "        #print(1)\n",
    "        return 1\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "#FUNCTION TO ACTUALLY GENERATE AN ARRAY OF DRAGONS\n",
    "def generateArrays(size):\n",
    "    \n",
    "    generated_dragons=[]\n",
    "    correctness=[]\n",
    "\n",
    "    for i in range(size):    \n",
    "\n",
    "        tempdragon=generateDragon()\n",
    "\n",
    "        tempcorrect=generateCorectness(tempdragon)\n",
    "\n",
    "        #print(mydragon,tempcorrect)\n",
    "\n",
    "        generated_dragons+=[tempdragon]\n",
    "        correctness+=[tempcorrect]\n",
    "    return generated_dragons, correctness\n",
    "\n",
    "        \n",
    "#GENERATE A TEST SET\n",
    "#testing_data=[]\n",
    "#testing_correctness=[]\n",
    "\n",
    "\n",
    "#generateArrays(100000,test_data,test_correctness)       \n",
    "    \n",
    "#for i in range(len(train_data)):\n",
    "    #print(train_data[i],train_correctness[i])\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lawful evil cloud dragon 0\n",
      "neutral neutral vortex dragon 1\n",
      "chaotic good bronze dragon 1\n",
      "chaotic good solar dragon 0\n",
      "neutral good void dragon 1\n",
      "chaotic good lunar dragon 0\n",
      "chaotic good crystal dragon 1\n",
      "chaotic good cloud dragon 1\n",
      "chaotic evil vortex dragon 0\n",
      "chaotic neutral solar dragon 0\n",
      "neutral neutral umbral dragon 1\n",
      "neutral neutral crystal dragon 1\n",
      "lawful evil void dragon 1\n",
      "lawful neutral silver dragon 1\n",
      "lawful neutral copper dragon 1\n",
      "lawful good vortex dragon 1\n",
      "lawful evil magma dragon 0\n",
      "neutral evil vortex dragon 1\n",
      "lawful neutral void dragon 1\n",
      "chaotic neutral blue dragon 1\n",
      "chaotic evil silver dragon 0\n",
      "lawful good bronze dragon 1\n",
      "lawful evil vortex dragon 1\n",
      "neutral good red dragon 0\n",
      "lawful good umbral dragon 0\n",
      "lawful good umbral dragon 0\n",
      "neutral good brine dragon 1\n",
      "chaotic neutral green dragon 1\n",
      "chaotic evil umbral dragon 1\n",
      "chaotic good white dragon 0\n",
      "neutral good black dragon 0\n",
      "chaotic good white dragon 0\n",
      "neutral evil copper dragon 0\n",
      "neutral neutral time dragon 1\n",
      "chaotic neutral copper dragon 1\n",
      "lawful evil blue dragon 1\n",
      "chaotic evil solar dragon 0\n",
      "lawful good magma dragon 0\n",
      "lawful good brine dragon 0\n",
      "lawful good lunar dragon 1\n",
      "lawful evil brine dragon 0\n",
      "chaotic good time dragon 0\n",
      "lawful evil silver dragon 0\n",
      "chaotic evil blue dragon 1\n",
      "chaotic evil blue dragon 1\n",
      "lawful neutral magma dragon 0\n",
      "chaotic neutral time dragon 0\n",
      "lawful neutral void dragon 1\n",
      "neutral neutral copper dragon 1\n",
      "chaotic neutral time dragon 0\n",
      "chaotic good silver dragon 1\n",
      "lawful good brass dragon 1\n",
      "neutral good vortex dragon 1\n",
      "lawful good green dragon 0\n",
      "lawful evil solar dragon 1\n",
      "lawful evil blue dragon 1\n",
      "chaotic evil brass dragon 0\n",
      "chaotic neutral gold dragon 1\n",
      "lawful good cloud dragon 0\n",
      "chaotic good solar dragon 0\n",
      "lawful evil vortex dragon 1\n",
      "lawful evil umbral dragon 0\n",
      "chaotic evil gold dragon 0\n",
      "lawful good black dragon 0\n",
      "chaotic evil copper dragon 0\n",
      "lawful evil bronze dragon 0\n",
      "neutral evil cloud dragon 1\n",
      "lawful evil copper dragon 0\n",
      "chaotic neutral time dragon 0\n",
      "chaotic good white dragon 0\n",
      "lawful evil gold dragon 0\n",
      "chaotic evil silver dragon 0\n",
      "lawful neutral white dragon 1\n",
      "chaotic good time dragon 0\n",
      "neutral neutral lunar dragon 1\n",
      "lawful good solar dragon 1\n",
      "neutral good time dragon 1\n",
      "chaotic good gold dragon 1\n",
      "chaotic good white dragon 0\n",
      "lawful neutral vortex dragon 1\n",
      "chaotic good vortex dragon 0\n",
      "lawful good time dragon 1\n",
      "neutral neutral void dragon 1\n",
      "lawful good brass dragon 1\n",
      "lawful evil brass dragon 0\n",
      "lawful evil time dragon 1\n",
      "neutral good brass dragon 1\n",
      "lawful evil crystal dragon 0\n",
      "chaotic neutral red dragon 1\n",
      "lawful good solar dragon 1\n",
      "lawful evil time dragon 1\n",
      "neutral neutral crystal dragon 1\n",
      "chaotic evil black dragon 1\n",
      "lawful evil gold dragon 0\n",
      "chaotic good silver dragon 1\n",
      "chaotic good void dragon 0\n",
      "lawful evil solar dragon 1\n",
      "lawful good umbral dragon 0\n",
      "lawful evil time dragon 1\n",
      "neutral evil cloud dragon 1\n",
      "40053 59947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#GENERATE DATA SETS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_size=100000\n",
    "train_data=[]\n",
    "train_correctness=[]\n",
    "\n",
    "test_size=100\n",
    "test_data=[]\n",
    "test_correctness=[]\n",
    "\n",
    "\n",
    "\n",
    "train_data,train_correctness = generateArrays(train_size)\n",
    "test_data,test_correctness = generateArrays(test_size)\n",
    "\n",
    "#for t in range(train_size):\n",
    "    #print(train_data[t],train_correctness[t])\n",
    "#print(\"DONE\")\n",
    "\n",
    "for t in range(test_size):\n",
    "    print(test_data[t],test_correctness[t])\n",
    "\n",
    "print(train_correctness.count(0),train_correctness.count(1))\n",
    "plt.plot([train_correctness.count(0),train_correctness.count(1)],'ro')\n",
    "plt.axis([-1,2,0,train_size])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "labels = \"misaligned dragons\",\"aligned dragons\"\n",
    "sizes = train_correctness.count(0),train_correctness.count(1)\n",
    "colors = 'yellow','aquamarine'\n",
    "explode=(0.1,0)\n",
    "plt.pie(sizes,explode=explode, labels=labels,colors=colors,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING STUFF\n",
    "import tensorflow as ts\n",
    "import keras as ks\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD,RMSprop,Adam \n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#MAGIC NUMBERS\n",
    "nr_neurons_in_first_layer=1000\n",
    "nr_neurons_in_second_layer=100\n",
    "nr_neurons_in_third_layer=10\n",
    "\n",
    "nr_classes=2\n",
    "optimizer=Adam()\n",
    "my_batch_size=100\n",
    "my_epochs=500\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6 14  1]\n",
      " [ 5  6 11  1]\n",
      " [ 5  6 24  1]\n",
      " ...\n",
      " [ 4  2 13  1]\n",
      " [ 4  2  9  1]\n",
      " [ 5  3 26  1]]\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#FITTIN DATA\n",
    "#tokenizing strings\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_data)\n",
    "index_list = tk.texts_to_sequences(train_data)\n",
    "train_data = pad_sequences(index_list)#x_train = pad_sequences(index_list, maxlen=maxlen)\n",
    "\n",
    "tk.fit_on_texts(test_data)\n",
    "index_list = tk.texts_to_sequences(test_data)\n",
    "test_data = pad_sequences(index_list)#x_train = pad_sequences(index_list, maxlen=maxlen)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "train_correctness=np_utils.to_categorical(train_correctness, nr_classes)\n",
    "\n",
    "test_correctness=np_utils.to_categorical(test_correctness, nr_classes)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data)\n",
    "print(test_correctness)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              5000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 106,132\n",
      "Trainable params: 106,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BULIDING A MODEL\n",
    "model=Sequential()\n",
    "model.add(Dense(nr_neurons_in_first_layer, input_shape=(4,), activation='relu' ))\n",
    "model.add(Dense(nr_neurons_in_second_layer, activation='relu'))\n",
    "model.add(Dense(nr_neurons_in_third_layer, activation='relu'))\n",
    "model.add(Dense(nr_classes, activation='softmax' ))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#COMPILING MODEL\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/500\n",
      " - 2s - loss: 0.2715 - acc: 0.9833 - val_loss: 0.2508 - val_acc: 0.9847\n",
      "Epoch 2/500\n",
      " - 2s - loss: 0.2711 - acc: 0.9833 - val_loss: 0.2485 - val_acc: 0.9847\n",
      "Epoch 3/500\n",
      " - 2s - loss: 0.2706 - acc: 0.9833 - val_loss: 0.2481 - val_acc: 0.9847\n",
      "Epoch 4/500\n",
      " - 2s - loss: 0.3481 - acc: 0.9737 - val_loss: 0.3275 - val_acc: 0.9800\n",
      "Epoch 5/500\n",
      " - 2s - loss: 0.3365 - acc: 0.9794 - val_loss: 0.3264 - val_acc: 0.9800\n",
      "Epoch 6/500\n",
      " - 2s - loss: 0.3355 - acc: 0.9794 - val_loss: 0.3256 - val_acc: 0.9800\n",
      "Epoch 7/500\n",
      " - 2s - loss: 0.3347 - acc: 0.9794 - val_loss: 0.3248 - val_acc: 0.9800\n",
      "Epoch 8/500\n",
      " - 2s - loss: 0.3341 - acc: 0.9794 - val_loss: 0.3243 - val_acc: 0.9800\n",
      "Epoch 9/500\n",
      " - 2s - loss: 0.3338 - acc: 0.9794 - val_loss: 0.3240 - val_acc: 0.9800\n",
      "Epoch 10/500\n",
      " - 2s - loss: 0.3335 - acc: 0.9794 - val_loss: 0.3238 - val_acc: 0.9800\n",
      "Epoch 11/500\n",
      " - 2s - loss: 0.3333 - acc: 0.9794 - val_loss: 0.3236 - val_acc: 0.9800\n",
      "Epoch 12/500\n",
      " - 2s - loss: 0.3331 - acc: 0.9794 - val_loss: 0.3234 - val_acc: 0.9800\n",
      "Epoch 13/500\n",
      " - 2s - loss: 0.3733 - acc: 0.9716 - val_loss: 0.3246 - val_acc: 0.9800\n",
      "Epoch 14/500\n",
      " - 2s - loss: 0.3337 - acc: 0.9794 - val_loss: 0.3237 - val_acc: 0.9800\n",
      "Epoch 15/500\n",
      " - 2s - loss: 0.3333 - acc: 0.9794 - val_loss: 0.3236 - val_acc: 0.9800\n",
      "Epoch 16/500\n",
      " - 2s - loss: 0.3332 - acc: 0.9794 - val_loss: 0.3235 - val_acc: 0.9800\n",
      "Epoch 17/500\n",
      " - 2s - loss: 0.3331 - acc: 0.9794 - val_loss: 0.3234 - val_acc: 0.9800\n",
      "Epoch 18/500\n",
      " - 2s - loss: 0.3331 - acc: 0.9794 - val_loss: 0.3234 - val_acc: 0.9800\n",
      "Epoch 19/500\n",
      " - 2s - loss: 0.3330 - acc: 0.9794 - val_loss: 0.3233 - val_acc: 0.9800\n",
      "Epoch 20/500\n",
      " - 2s - loss: 0.3330 - acc: 0.9794 - val_loss: 0.3233 - val_acc: 0.9800\n",
      "Epoch 21/500\n",
      " - 2s - loss: 0.3330 - acc: 0.9794 - val_loss: 0.3233 - val_acc: 0.9800\n",
      "Epoch 22/500\n",
      " - 2s - loss: 0.3329 - acc: 0.9794 - val_loss: 0.3233 - val_acc: 0.9800\n",
      "Epoch 23/500\n",
      " - 2s - loss: 0.3329 - acc: 0.9794 - val_loss: 0.3232 - val_acc: 0.9800\n",
      "Epoch 24/500\n",
      " - 2s - loss: 0.2475 - acc: 0.9730 - val_loss: 0.0834 - val_acc: 0.9953\n",
      "Epoch 25/500\n",
      " - 2s - loss: 0.0711 - acc: 0.9952 - val_loss: 0.0860 - val_acc: 0.9953\n",
      "Epoch 26/500\n",
      " - 2s - loss: 0.0695 - acc: 0.9954 - val_loss: 0.0815 - val_acc: 0.9953\n",
      "Epoch 27/500\n",
      " - 2s - loss: 0.0674 - acc: 0.9959 - val_loss: 0.0795 - val_acc: 0.9953\n",
      "Epoch 28/500\n",
      " - 2s - loss: 0.0675 - acc: 0.9955 - val_loss: 0.0796 - val_acc: 0.9953\n",
      "Epoch 29/500\n",
      " - 2s - loss: 0.1742 - acc: 0.9844 - val_loss: 0.3252 - val_acc: 0.9800\n",
      "Epoch 30/500\n",
      " - 2s - loss: 0.3347 - acc: 0.9794 - val_loss: 0.3246 - val_acc: 0.9800\n",
      "Epoch 31/500\n",
      " - 2s - loss: 0.3344 - acc: 0.9794 - val_loss: 0.3245 - val_acc: 0.9800\n",
      "Epoch 32/500\n",
      " - 2s - loss: 0.2589 - acc: 0.9753 - val_loss: 0.0216 - val_acc: 0.9918\n",
      "Epoch 33/500\n",
      " - 2s - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "Epoch 34/500\n",
      " - 2s - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0168 - val_acc: 0.9877\n",
      "Epoch 35/500\n",
      " - 2s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0126 - val_acc: 0.9953\n",
      "Epoch 36/500\n",
      " - 2s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0086 - val_acc: 0.9960\n",
      "Epoch 37/500\n",
      " - 2s - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0089 - val_acc: 0.9953\n",
      "Epoch 38/500\n",
      " - 2s - loss: 0.0238 - acc: 0.9934 - val_loss: 0.0058 - val_acc: 0.9953\n",
      "Epoch 39/500\n",
      " - 2s - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      " - 2s - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0084 - val_acc: 0.9960\n",
      "Epoch 41/500\n",
      " - 2s - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      " - 2s - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      " - 2s - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0050 - val_acc: 0.9953\n",
      "Epoch 44/500\n",
      " - 2s - loss: 0.2470 - acc: 0.9823 - val_loss: 0.2490 - val_acc: 0.9847\n",
      "Epoch 45/500\n",
      " - 2s - loss: 0.2721 - acc: 0.9829 - val_loss: 0.2490 - val_acc: 0.9847\n",
      "Epoch 46/500\n",
      " - 2s - loss: 0.2885 - acc: 0.9784 - val_loss: 0.2508 - val_acc: 0.9847\n",
      "Epoch 47/500\n",
      " - 2s - loss: 0.2727 - acc: 0.9827 - val_loss: 0.2502 - val_acc: 0.9847\n",
      "Epoch 48/500\n",
      " - 2s - loss: 0.2722 - acc: 0.9829 - val_loss: 0.2497 - val_acc: 0.9847\n",
      "Epoch 49/500\n",
      " - 2s - loss: 0.2798 - acc: 0.9805 - val_loss: 0.2609 - val_acc: 0.9800\n",
      "Epoch 50/500\n",
      " - 2s - loss: 0.2720 - acc: 0.9829 - val_loss: 0.2491 - val_acc: 0.9847\n",
      "Epoch 51/500\n",
      " - 2s - loss: 0.2713 - acc: 0.9832 - val_loss: 0.2488 - val_acc: 0.9847\n",
      "Epoch 52/500\n",
      " - 2s - loss: 0.2709 - acc: 0.9832 - val_loss: 0.2483 - val_acc: 0.9847\n",
      "Epoch 53/500\n",
      " - 2s - loss: 0.2837 - acc: 0.9803 - val_loss: 0.2487 - val_acc: 0.9847\n",
      "Epoch 54/500\n",
      " - 2s - loss: 0.2705 - acc: 0.9833 - val_loss: 0.2482 - val_acc: 0.9847\n",
      "Epoch 55/500\n",
      " - 2s - loss: 0.2704 - acc: 0.9833 - val_loss: 0.2480 - val_acc: 0.9847\n",
      "Epoch 56/500\n",
      " - 2s - loss: 0.2704 - acc: 0.9832 - val_loss: 0.2479 - val_acc: 0.9847\n",
      "Epoch 57/500\n",
      " - 2s - loss: 0.2702 - acc: 0.9833 - val_loss: 0.2479 - val_acc: 0.9847\n",
      "Epoch 58/500\n",
      " - 2s - loss: 0.3032 - acc: 0.9738 - val_loss: 0.2594 - val_acc: 0.9800\n",
      "Epoch 59/500\n",
      " - 2s - loss: 0.2800 - acc: 0.9782 - val_loss: 0.2567 - val_acc: 0.9800\n",
      "Epoch 60/500\n",
      " - 2s - loss: 0.2788 - acc: 0.9788 - val_loss: 0.2480 - val_acc: 0.9847\n",
      "Epoch 61/500\n",
      " - 2s - loss: 0.2703 - acc: 0.9833 - val_loss: 0.2480 - val_acc: 0.9847\n",
      "Epoch 62/500\n",
      " - 2s - loss: 0.2224 - acc: 0.9769 - val_loss: 0.0098 - val_acc: 0.9960\n",
      "Epoch 63/500\n",
      " - 2s - loss: 0.0080 - acc: 0.9960 - val_loss: 0.0123 - val_acc: 0.9953\n",
      "Epoch 64/500\n",
      " - 2s - loss: 0.0084 - acc: 0.9958 - val_loss: 0.0087 - val_acc: 0.9913\n",
      "Epoch 65/500\n",
      " - 2s - loss: 0.0089 - acc: 0.9953 - val_loss: 0.0132 - val_acc: 0.9953\n",
      "Epoch 66/500\n",
      " - 2s - loss: 0.0084 - acc: 0.9956 - val_loss: 0.0083 - val_acc: 0.9953\n",
      "Epoch 67/500\n",
      " - 2s - loss: 0.0076 - acc: 0.9961 - val_loss: 0.0181 - val_acc: 0.9953\n",
      "Epoch 68/500\n",
      " - 2s - loss: 0.0087 - acc: 0.9960 - val_loss: 0.0131 - val_acc: 0.9919\n",
      "Epoch 69/500\n",
      " - 2s - loss: 0.0281 - acc: 0.9921 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      " - 2s - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0045 - val_acc: 0.9960\n",
      "Epoch 71/500\n",
      " - 2s - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0046 - val_acc: 0.9953\n",
      "Epoch 72/500\n",
      " - 2s - loss: 0.0275 - acc: 0.9931 - val_loss: 0.0187 - val_acc: 0.9918\n",
      "Epoch 73/500\n",
      " - 2s - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      " - 2s - loss: 0.0274 - acc: 0.9938 - val_loss: 0.0076 - val_acc: 0.9965\n",
      "Epoch 75/500\n",
      " - 2s - loss: 0.0051 - acc: 0.9998 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      " - 2s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      " - 2s - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      " - 2s - loss: 0.0016 - acc: 0.9999 - val_loss: 8.7859e-04 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      " - 2s - loss: 7.7781e-04 - acc: 1.0000 - val_loss: 5.9728e-04 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      " - 2s - loss: 0.0460 - acc: 0.9938 - val_loss: 0.1201 - val_acc: 0.9927\n",
      "Epoch 81/500\n",
      " - 2s - loss: 0.1323 - acc: 0.9919 - val_loss: 0.1195 - val_acc: 0.9927\n",
      "Epoch 82/500\n",
      " - 2s - loss: 0.1319 - acc: 0.9919 - val_loss: 0.1195 - val_acc: 0.9927\n",
      "Epoch 83/500\n",
      " - 2s - loss: 0.1316 - acc: 0.9919 - val_loss: 0.1191 - val_acc: 0.9927\n",
      "Epoch 84/500\n",
      " - 2s - loss: 0.1315 - acc: 0.9919 - val_loss: 0.1190 - val_acc: 0.9927\n",
      "Epoch 85/500\n",
      " - 2s - loss: 0.1313 - acc: 0.9919 - val_loss: 0.1190 - val_acc: 0.9927\n",
      "Epoch 86/500\n",
      " - 2s - loss: 0.1265 - acc: 0.9894 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      " - 2s - loss: 5.5597e-04 - acc: 1.0000 - val_loss: 4.0306e-04 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      " - 2s - loss: 3.3009e-04 - acc: 1.0000 - val_loss: 2.7574e-04 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      " - 2s - loss: 2.3644e-04 - acc: 1.0000 - val_loss: 1.9141e-04 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      " - 2s - loss: 1.6996e-04 - acc: 1.0000 - val_loss: 1.4884e-04 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      " - 2s - loss: 1.3701e-04 - acc: 1.0000 - val_loss: 1.2796e-04 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      " - 2s - loss: 1.1018e-04 - acc: 1.0000 - val_loss: 9.7031e-05 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      " - 2s - loss: 8.8724e-05 - acc: 1.0000 - val_loss: 8.4064e-05 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      " - 2s - loss: 7.1197e-05 - acc: 1.0000 - val_loss: 6.4857e-05 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      " - 2s - loss: 5.5153e-05 - acc: 1.0000 - val_loss: 4.5002e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      " - 2s - loss: 0.0388 - acc: 0.9932 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      " - 2s - loss: 8.2947e-04 - acc: 1.0000 - val_loss: 5.0130e-04 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      " - 2s - loss: 3.6954e-04 - acc: 1.0000 - val_loss: 2.8422e-04 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      " - 2s - loss: 2.4728e-04 - acc: 1.0000 - val_loss: 2.0088e-04 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      " - 2s - loss: 1.8872e-04 - acc: 1.0000 - val_loss: 1.6456e-04 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      " - 2s - loss: 1.5143e-04 - acc: 1.0000 - val_loss: 2.0018e-04 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      " - 2s - loss: 1.2683e-04 - acc: 1.0000 - val_loss: 1.1817e-04 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      " - 2s - loss: 1.0327e-04 - acc: 1.0000 - val_loss: 9.2184e-05 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      " - 2s - loss: 8.1829e-05 - acc: 1.0000 - val_loss: 6.6425e-05 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      " - 2s - loss: 6.3552e-05 - acc: 1.0000 - val_loss: 4.9627e-05 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      " - 2s - loss: 4.5333e-05 - acc: 1.0000 - val_loss: 1.7014e-04 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      " - 2s - loss: 0.2977 - acc: 0.9780 - val_loss: 0.2484 - val_acc: 0.9847\n",
      "Epoch 108/500\n",
      " - 2s - loss: 0.2709 - acc: 0.9832 - val_loss: 0.2485 - val_acc: 0.9847\n",
      "Epoch 109/500\n",
      " - 2s - loss: 0.2707 - acc: 0.9832 - val_loss: 0.2481 - val_acc: 0.9847\n",
      "Epoch 110/500\n",
      " - 2s - loss: 0.2702 - acc: 0.9832 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 111/500\n",
      " - 2s - loss: 0.2699 - acc: 0.9833 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 112/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 113/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 114/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 115/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2475 - val_acc: 0.9847\n",
      "Epoch 116/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9847\n",
      "Epoch 117/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9847\n",
      "Epoch 118/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9847\n",
      "Epoch 119/500\n",
      " - 2s - loss: 0.2698 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9847\n",
      "Epoch 120/500\n",
      " - 2s - loss: 0.2016 - acc: 0.9842 - val_loss: 0.1188 - val_acc: 0.9927\n",
      "Epoch 121/500\n",
      " - 2s - loss: 0.1313 - acc: 0.9919 - val_loss: 0.1188 - val_acc: 0.9927\n",
      "Epoch 122/500\n",
      " - 2s - loss: 0.1312 - acc: 0.9919 - val_loss: 0.1187 - val_acc: 0.9927\n",
      "Epoch 123/500\n",
      " - 2s - loss: 0.1312 - acc: 0.9919 - val_loss: 0.1187 - val_acc: 0.9927\n",
      "Epoch 124/500\n",
      " - 2s - loss: 0.1312 - acc: 0.9919 - val_loss: 0.1186 - val_acc: 0.9927\n",
      "Epoch 125/500\n",
      " - 2s - loss: 0.1311 - acc: 0.9919 - val_loss: 0.1186 - val_acc: 0.9927\n",
      "Epoch 126/500\n",
      " - 2s - loss: 0.2174 - acc: 0.9840 - val_loss: 0.2170 - val_acc: 0.9866\n",
      "Epoch 127/500\n",
      " - 2s - loss: 0.1999 - acc: 0.9876 - val_loss: 0.2170 - val_acc: 0.9866\n",
      "Epoch 128/500\n",
      " - 2s - loss: 0.1998 - acc: 0.9876 - val_loss: 0.2169 - val_acc: 0.9866\n",
      "Epoch 129/500\n",
      " - 2s - loss: 0.1998 - acc: 0.9876 - val_loss: 0.2169 - val_acc: 0.9866\n",
      "Epoch 130/500\n",
      " - 2s - loss: 0.1998 - acc: 0.9876 - val_loss: 0.2169 - val_acc: 0.9866\n",
      "Epoch 131/500\n",
      " - 2s - loss: 0.1998 - acc: 0.9876 - val_loss: 0.2169 - val_acc: 0.9866\n",
      "Epoch 132/500\n",
      " - 2s - loss: 0.1997 - acc: 0.9876 - val_loss: 0.2169 - val_acc: 0.9866\n",
      "Epoch 133/500\n",
      " - 2s - loss: 0.1865 - acc: 0.9846 - val_loss: 0.1362 - val_acc: 0.9916\n",
      "Epoch 134/500\n",
      " - 2s - loss: 0.1280 - acc: 0.9921 - val_loss: 0.1360 - val_acc: 0.9916\n",
      "Epoch 135/500\n",
      " - 2s - loss: 0.1279 - acc: 0.9921 - val_loss: 0.1359 - val_acc: 0.9916\n",
      "Epoch 136/500\n",
      " - 2s - loss: 0.1278 - acc: 0.9921 - val_loss: 0.1358 - val_acc: 0.9916\n",
      "Epoch 137/500\n",
      " - 2s - loss: 0.1278 - acc: 0.9921 - val_loss: 0.1357 - val_acc: 0.9916\n",
      "Epoch 138/500\n",
      " - 2s - loss: 0.1277 - acc: 0.9921 - val_loss: 0.1356 - val_acc: 0.9916\n",
      "Epoch 139/500\n",
      " - 2s - loss: 0.1276 - acc: 0.9921 - val_loss: 0.1356 - val_acc: 0.9916\n",
      "Epoch 140/500\n",
      " - 2s - loss: 0.1240 - acc: 0.9883 - val_loss: 0.0760 - val_acc: 0.9953\n",
      "Epoch 141/500\n",
      " - 2s - loss: 0.0665 - acc: 0.9959 - val_loss: 0.0760 - val_acc: 0.9953\n",
      "Epoch 142/500\n",
      " - 2s - loss: 0.0665 - acc: 0.9959 - val_loss: 0.0759 - val_acc: 0.9953\n",
      "Epoch 143/500\n",
      " - 2s - loss: 0.0665 - acc: 0.9959 - val_loss: 0.0759 - val_acc: 0.9953\n",
      "Epoch 144/500\n",
      " - 2s - loss: 0.0664 - acc: 0.9959 - val_loss: 0.0759 - val_acc: 0.9953\n",
      "Epoch 145/500\n",
      " - 2s - loss: 0.0664 - acc: 0.9959 - val_loss: 0.0759 - val_acc: 0.9953\n",
      "Epoch 146/500\n",
      " - 2s - loss: 0.0664 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 147/500\n",
      " - 2s - loss: 0.0664 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 148/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 149/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 150/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 151/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 152/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 153/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 154/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 155/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 156/500\n",
      " - 2s - loss: 0.1035 - acc: 0.9905 - val_loss: 0.0759 - val_acc: 0.9953\n",
      "Epoch 157/500\n",
      " - 2s - loss: 0.0664 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 158/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 159/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 160/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 161/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 162/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 163/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 164/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 165/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 166/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 167/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 168/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 169/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 170/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 171/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 172/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 173/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 174/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 175/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 176/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 177/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 178/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 179/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 180/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 181/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 182/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 183/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 184/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 185/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 186/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 187/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 188/500\n",
      " - 2s - loss: 0.0663 - acc: 0.9959 - val_loss: 0.0758 - val_acc: 0.9953\n",
      "Epoch 189/500\n",
      " - 2s - loss: 0.2329 - acc: 0.9819 - val_loss: 0.2926 - val_acc: 0.9819\n",
      "Epoch 190/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2926 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2926 - val_acc: 0.9819\n",
      "Epoch 192/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 193/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 194/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 195/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 196/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 197/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 198/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 199/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 200/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 201/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 202/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 203/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 204/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 205/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 206/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 207/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 208/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 209/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 210/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 211/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 212/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 213/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 214/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 215/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 216/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 217/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 218/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 219/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 220/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 221/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 222/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 223/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 224/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 225/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 226/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 227/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 228/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 229/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 230/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 231/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 232/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 233/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 234/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 235/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 236/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 237/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 238/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 239/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 240/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 241/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 242/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 243/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 244/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 245/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 246/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 247/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 248/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 249/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 250/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 251/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 252/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 253/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 254/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 255/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 256/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 257/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 258/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 259/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 260/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 261/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 262/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 263/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 264/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 265/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 266/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 267/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 268/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 269/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 270/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 271/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 272/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 273/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 274/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 275/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 276/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 277/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 278/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 279/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 280/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 281/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 282/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 283/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 284/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 285/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 286/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 288/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 289/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 290/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 291/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 292/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 293/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 294/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 295/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 296/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 297/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 298/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 299/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 300/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 301/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 302/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 303/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 304/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 305/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 306/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 307/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 308/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 309/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 310/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 311/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 312/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 313/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 314/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 315/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 316/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 317/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 318/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 319/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 320/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 321/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 322/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 323/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 324/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 325/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 326/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 327/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 328/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 329/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 330/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 331/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 332/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 333/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 334/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 335/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 336/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 337/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 338/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 339/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 340/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 341/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 342/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 343/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 344/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 345/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 346/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 347/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 348/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 349/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 350/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 351/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 352/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 353/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 354/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 355/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 356/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 357/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 358/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 359/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 360/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 361/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 362/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 363/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 364/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 365/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 366/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 367/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 368/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 369/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 370/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 371/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 372/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 373/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 374/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 375/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 376/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 377/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 378/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 379/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 380/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 381/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 382/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 384/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 385/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 386/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 387/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 388/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 389/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 390/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 391/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 392/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 393/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 394/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 395/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 396/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 397/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 398/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 399/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 400/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 401/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 402/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 403/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 404/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 405/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 406/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 407/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 408/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 409/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 410/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 411/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 412/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 413/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 414/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 415/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 416/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 417/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 418/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 419/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 420/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 421/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 422/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 423/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 424/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 425/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 426/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 427/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 428/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 429/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 430/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 431/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 432/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 433/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 434/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 435/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 436/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 437/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 438/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 439/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 440/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 441/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 442/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 443/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 444/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 445/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 446/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 447/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 448/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 449/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 450/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 451/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 452/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 453/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 454/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 455/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 456/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 457/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 458/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 459/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 460/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 461/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 462/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 463/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 464/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 465/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 466/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 467/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 468/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 469/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 470/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 471/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 472/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 473/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 474/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 475/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 476/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 477/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 478/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 480/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 481/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 482/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 483/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 484/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 485/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 486/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 487/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 488/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 489/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 490/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 491/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 492/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 493/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 494/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 495/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 496/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 497/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 498/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 499/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "Epoch 500/500\n",
      " - 2s - loss: 0.2627 - acc: 0.9837 - val_loss: 0.2925 - val_acc: 0.9819\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_train, y_train_onehot, batch_size=b_size, epochs=epoch, verbose=1, validation_split=0.2)\n",
    "\n",
    "history= model.fit(train_data,train_correctness, batch_size=my_batch_size, epochs=my_epochs, verbose=2, validation_split=0.2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 120us/step\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data,test_correctness)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  2.578895263671875\n",
      "accuracy:  0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \",score[0])\n",
    "print(\"accuracy: \",score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
